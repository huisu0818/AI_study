{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP(Contrastive Language-Image Pre-Training): Learning Transferable Visual Models From Natural Language Supervision\n",
    "\n",
    "[ Feb 2021, Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever ]\n",
    "\n",
    "논문링크: https://paperswithcode.com/paper/learning-transferable-visual-models-from\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./fig1.png\" alt=\"nn\" width=\"600\">\n",
    "</div><br>\n",
    "\n",
    "# BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation\n",
    "\n",
    "[ Jan 2022, Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi ]\n",
    "\n",
    "논문링크: https://paperswithcode.com/paper/blip-bootstrapping-language-image-pre\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./fig2.png\" alt=\"nn\" width=\"600\">\n",
    "</div><br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./fig3.png\" alt=\"nn\" width=\"600\">\n",
    "</div><br>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
