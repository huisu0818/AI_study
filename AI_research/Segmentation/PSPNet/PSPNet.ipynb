{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet (Pyramid Scene Parsing Network)\n",
    "\n",
    "Pyramid Scene Parsing Network [ CVPR 2017  ·  Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia ]\n",
    "\n",
    "https://paperswithcode.com/paper/pyramid-scene-parsing-network\n",
    "\n",
    "https://mvje.tistory.com/33\n",
    "\n",
    "https://gaussian37.github.io/vision-segmentation-pspnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ Abstract ]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PSPN1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mismatched Relationship: contextual information과 맞지 않게 오분류\n",
    "    - ex: 호수 위의 자동차\n",
    "\n",
    "- Confusion Categories: 헷갈릴 수 있는 픽셀 오분류\n",
    "    - ex: builing으로 분류된 픽셀 내부에 skyscraper로 오분류 된 경우\n",
    "\n",
    "- Inconspicuous Classes: 눈에 잘 띄지 않는 물체의 픽셀 오분류. \n",
    "    - ex: texture가 비슷한 이불과 베개에서 베개를 분류하지 못하는 경우\n",
    "\n",
    "- FCN은 이러한 문제점들을 갖고 있었고, PSPNet에서는 Global Context를 고려하여 Segmentation 하고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ Architecture ]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PSPN2.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PSPN3.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pyramid Pooling Module: \n",
    "    - 기존 feature map의 채널 사이즈가 N 일때 pooling된 feature 사이즈는 각가 1x1xN, 2x2xN, 3x3xN, 6x6xN이다.\n",
    "    - 1x1xN으로 pooling된 feature의 경우 이미지 전체에 대한 global context를 담고 있다.\n",
    "    - 2x2xN의 경우 이미지 전체를 4개의 영역으로 나누어 영역별 global context 를 내포합니다. \n",
    "    - 이렇듯 여러 사이즈로 pooling을 한 결과가 이미지 전체를 여러 스케일의 그리드로 나누어 global context를 가지도록 만든다.\n",
    "    - 마지막으로 pooling된 feature들을 conv 에 통과시켜 N개의 채널을 N/4 개의 채널로 바꿔줘서 기존 feature와 global context information을 가지는 feature의 채널 수가 1:1이 되도록 맞춰줍니다. \n",
    "\n",
    "- 두번째 그림은 Pooling을 통하여 어떻게 global contextual information을 얻는지 설명합니다. 동그라미 Feature를 가진 Feature map을 4개의 sub-region으로 나눕니다. 나누어진 각 sub-region에 존재하는 pixel 값들을 평균(Ave Pooling)을 2×2 배열에 입력합니다. 그러면 위 그림과 같이 각 sub-region의 전체적인 특징이 나타낼 수 있습니다. 즉, 자동차 또는 보트의 feature로 추정되는 local contextual information의 근처에 물이 있다면 Max/Average Pooling을 통해 구한 global contextual information에 물의 feature가 포함되어 최종적으로 자동차가 아닌 보트로 추정하게 되는 원리입니다. 즉, 형상과 주변 상황을 모두 고려할 수 있기 때문에 Segmentaion에 있어서 더 좋은 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ Performance ]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 사이즈로 pooling 할 수록, max 보다는 average pooling을 할 때, conv로 dimension을 줄일 때 성능이 좋아지는 것을 볼 수 있습니다.\n",
    "\n",
    "- max pooling은 하나의 강한 값에만 영향을 받기 때문에 context information을 담기에 적절하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
